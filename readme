

# ğŸ¤– TalentScout â€“ AI Hiring Assistant Chatbot

## ğŸ“Œ Project Overview

TalentScout Hiring Assistant is an AI-powered chatbot developed to streamline the initial screening process for technical candidates. The chatbot interacts with applicants, collects essential details, and dynamically generates technical interview questions based on the candidate's declared tech stack.

This project demonstrates:

* Large Language Model (LLM) integration using Groq API
* Prompt engineering for structured information collection
* Context-aware conversational flow
* Secure handling of candidate data
* Cloud deployment readiness (AWS EC2)

---

# ğŸ¯ Objective

To design an intelligent conversational assistant that:

1. Collects structured candidate information
2. Generates tailored technical interview questions
3. Maintains conversational context
4. Handles unexpected input gracefully
5. Provides a seamless user experience

---

# ğŸ—ï¸ System Architecture

```
Streamlit UI
      â†“
Conversation Manager (Session Memory)
      â†“
Groq LLM (Llama 3.1)
      â†“
Candidate Data Storage (JSON-based simulation)
```

---

# ğŸ› ï¸ Tech Stack

## ğŸ’» Programming Language

* Python 3.10+

## ğŸ“š Libraries Used

* streamlit â€“ Frontend interface
* groq â€“ LLM integration
* python-dotenv â€“ Secure API key management
* json â€“ Simulated data storage

## ğŸ¤– LLM Model Used

* `llama-3.1-8b-instant` (via Groq API)

---

# ğŸ”¥ Features Implemented

## 1ï¸âƒ£ Greeting & Role Introduction

* Professional welcome message
* Explains purpose of the chatbot
* Guides candidate through screening process

---

## 2ï¸âƒ£ Candidate Information Collection

The chatbot collects:

* Full Name
* Email Address
* Phone Number
* Years of Experience
* Desired Position
* Current Location
* Tech Stack

Structured prompting ensures accurate information capture.

---

## 3ï¸âƒ£ Dynamic Technical Question Generation

Once the tech stack is declared, the chatbot:

* Identifies listed technologies
* Generates 3â€“5 technical questions per technology
* Includes scenario-based and real-world questions
* Maintains moderate interview-level difficulty

Example:

If candidate enters:

```
Python, Django, MySQL
```

The chatbot generates:

* Python OOP and memory management questions
* Django ORM and middleware questions
* MySQL indexing and query optimization questions

---

## 4ï¸âƒ£ Context Management

The application uses Streamlit session state to:

* Maintain full conversation history
* Enable coherent follow-up interactions
* Avoid loss of conversational flow

---

## 5ï¸âƒ£ Fallback Mechanism

If user input is:

* Unclear
* Irrelevant
* Outside hiring scope

The chatbot:

* Politely requests clarification
* Avoids deviating from its purpose
* Maintains professional tone

---

## 6ï¸âƒ£ Conversation Termination

If candidate types:

```
exit
quit
bye
```

The chatbot:

* Gracefully concludes
* Thanks the candidate
* Informs about next steps

---

# ğŸ§  Prompt Engineering Strategy

## System Prompt Design

The system prompt enforces:

* Hiring assistant role restriction
* Structured information collection
* Tech-stack-based question generation
* Professional tone control
* Purpose-bound responses

Temperature set to:

```
0.3
```

This ensures:

* Deterministic responses
* Controlled output
* Reduced hallucination

---

## Technical Question Prompt Strategy

Dynamic prompt template:

* Injects declared tech stack
* Forces question count limit
* Encourages scenario-based assessment
* Prevents generic responses

---

# ğŸ” Data Privacy & Security

## Sensitive Data Handling

* API keys stored in `.env`
* `.env` excluded via `.gitignore`
* No hardcoded secrets
* Simulated backend storage

## Compliance Considerations

* Only simulated candidate data used
* No external database storing real user data
* Designed to follow GDPR best practices

---

# ğŸš€ Installation & Setup

## 1ï¸âƒ£ Clone Repository

```
https://github.com/Reddy0402/hiring_assistant
```

---

## 2ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
venv\Scripts\activate  (Windows)
```

---

## 3ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

---

## 4ï¸âƒ£ Create .env File

```
GROQ_API_KEY=your_actual_groq_api_key
```

---

## 5ï¸âƒ£ Run Application

```
streamlit run app.py
```

Open in browser:

```
http://localhost:8501
```

---

# â˜ï¸ AWS Deployment (EC2)

The application can be deployed on AWS EC2:

1. Launch Ubuntu EC2 instance
2. Install Python & Git
3. Clone repository
4. Install dependencies
5. Set environment variable:

   ```
   export GROQ_API_KEY="your_key"
   ```
6. Run:

   ```
   streamlit run app.py --server.port 8501 --server.address 0.0.0.0
   ```

Access via:

```
http://your-ec2-public-ip:8501
```

---

# ğŸ“‚ Project Structure

```
talentscout-hiring-assistant/
â”‚
â”œâ”€â”€ app.py                # Streamlit UI & conversation flow
â”œâ”€â”€ llm_handler.py        # Groq API integration
â”œâ”€â”€ prompts.py            # Prompt engineering templates
â”œâ”€â”€ data_store.py         # Simulated data storage
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

# ğŸ§© Challenges Faced & Solutions

## Challenge 1: Maintaining Context

Solution: Used Streamlit session state to store message history.

## Challenge 2: Structured Data Collection

Solution: Designed system prompts enforcing required fields sequentially.

## Challenge 3: Avoiding Off-Topic Responses

Solution: Role-constrained system prompt with purpose restriction.

## Challenge 4: Model Deprecation

Solution: Updated to llama-3.1-8b-instant after decommission notice.

---

# ğŸ”® Future Enhancements

* Sentiment analysis integration
* Multilingual support
* Database integration (PostgreSQL)
* Resume parsing using NLP
* Admin dashboard for recruiters
* Docker containerization


---

# ğŸ“Š Evaluation Alignment

This project satisfies:

âœ” LLM integration
âœ” Prompt engineering
âœ” Context management
âœ” Structured data collection
âœ” Secure key handling
âœ” Clean UI implementation
âœ” Cloud deployment capability

---

# ğŸ¥ Demo

(Optional)

* Loom walkthrough link
* AWS live demo link

---

# ğŸ‘¨â€ğŸ’» Author

Sai Teja Reddy
AI/ML Engineering Student
Specialization: Artificial Intelligence & Machine Learning

